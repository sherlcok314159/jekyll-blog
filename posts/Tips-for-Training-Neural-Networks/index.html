<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Tips for Training Neural Networks" /><meta property="og:locale" content="en" /><meta name="description" content="Recently, I have read a blog about training neural networks (simplified as NN in the rest part of this post) and it is really amazing. I am going to add my own experience in this post along with summarizing that blog’s interesting part." /><meta property="og:description" content="Recently, I have read a blog about training neural networks (simplified as NN in the rest part of this post) and it is really amazing. I am going to add my own experience in this post along with summarizing that blog’s interesting part." /><link rel="canonical" href="https://www.yunpengtai.top/posts/Tips-for-Training-Neural-Networks/" /><meta property="og:url" content="https://www.yunpengtai.top/posts/Tips-for-Training-Neural-Networks/" /><meta property="og:site_name" content="Yunpeng Tai" /><meta property="og:image" content="https://s2.loli.net//2022/07/30/WhxM7r28QR1PLOY.jpg" /><meta property="og:image:height" content="100" /><meta property="og:image:width" content="600" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-07-30T19:43:00+08:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://s2.loli.net//2022/07/30/WhxM7r28QR1PLOY.jpg" /><meta property="twitter:title" content="Tips for Training Neural Networks" /><meta name="twitter:site" content="@TonySta14611077" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-08-01T14:28:05+08:00","datePublished":"2022-07-30T19:43:00+08:00","description":"Recently, I have read a blog about training neural networks (simplified as NN in the rest part of this post) and it is really amazing. I am going to add my own experience in this post along with summarizing that blog’s interesting part.","headline":"Tips for Training Neural Networks","image":{"width":600,"height":100,"url":"https://www.yunpengtai.top/2022/07/30/WhxM7r28QR1PLOY.jpg","@type":"imageObject"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.yunpengtai.top/posts/Tips-for-Training-Neural-Networks/"},"url":"https://www.yunpengtai.top/posts/Tips-for-Training-Neural-Networks/"}</script><title>Tips for Training Neural Networks | Yunpeng Tai</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Yunpeng Tai"><meta name="application-name" content="Yunpeng Tai"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://avatars.githubusercontent.com/u/76043326?s=400&u=1f9b3c508db6b5caec736e7c1edb42ba76e2f2a1&v=4" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Yunpeng Tai</a></div><div class="site-subtitle font-italic">Learn to think</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/sherlcok314159" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/TonySta14611077" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['yunpengtai.typ','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Tips for Training Neural Networks</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Tips for Training Neural Networks</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1659181380" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jul 30, 2022 </em> </span> <span> Updated <em class="" data-ts="1659335285" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Aug 1, 2022 </em> </span><div class="mt-3 mb-3"> <img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 600 100'%3E%3C/svg%3E" data-src="https://s2.loli.net//2022/07/30/WhxM7r28QR1PLOY.jpg" class="preview-img bg" alt="Preview Image" width="600" height="100" data-proofer-ignore></div><div class="d-flex justify-content-between"> <span></span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1812 words"> <em>10 min</em> read</span></div></div></div><div class="post-content"><p>Recently, I have read a <a href="http://karpathy.github.io/2019/04/25/recipe/">blog</a> about training neural networks (simplified as NN in the rest part of this post) and it is really amazing. I am going to add my own <code class="language-plaintext highlighter-rouge">experience</code> in this post along with <code class="language-plaintext highlighter-rouge">summarizing</code> that blog’s interesting part.</p><p>Nowadays, it seems like that training NN is extremely easy for there are plenty of free <code class="language-plaintext highlighter-rouge">frameworks</code> which are simple to use (e.g. PyTorch, Numpy, Tensorflow). Well, training NN is easy when you are <code class="language-plaintext highlighter-rouge">copying</code> others’ work (e.g. reproducing a BERT) because everything is there for you. However, when designing a NN or facing a new task, you are most probably trapped somewhere.</p><p>And this blog is meant to guide you to handle new problems.</p><p>Let’s first begin with some basic rules. Hope you guys enjoy it!</p><ol><li><b>Rush into training neural networks leads to suffering.</b> Training NN is not like writing the common code. For instance, if you plug in a int while it needs a string, errors just come out. However, writing the code about NN can not be so easy for it won’t show you bugs <code class="language-plaintext highlighter-rouge">automatically</code> (only if you make big mistakes).<li><b>Sweating the details always pays off.</b> Someone may say the details are <code class="language-plaintext highlighter-rouge">infinite</code> and can stop you from marching. Note that the details mentioned here are all necessary instead of some <code class="language-plaintext highlighter-rouge">trivialities</code>. And sweating the details can reduce your pain.<li><b>Observation leads to intuition. </b> Sadly, if you just keep thinking about something, inspiration will never come to you. For instance, if you want to upgrade the algorithm, you had better observe the data where the algorithm fails instead of just thinking about the algorithm.<li><b>Trusting your intuition instead of your implementation. </b> Sometimes when you come up with a new idea, the implementation of it may go wrong to some degree. When the result is <code class="language-plaintext highlighter-rouge">opposite</code> to your <code class="language-plaintext highlighter-rouge">assumption</code>, always check your code first before doubting your idea.<li><b>Quicker, then better.</b> When you are trying to test your hypothesis, use the most <code class="language-plaintext highlighter-rouge">efficient</code> way to verify it as <code class="language-plaintext highlighter-rouge">fast</code> as possible.</ol><p>Then let us go through concrete parts.</p><h3 id="1-familiar-with-data"><span class="mr-2">1. Familiar with Data</span><a href="#1-familiar-with-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>At this stage, you need to do some basic analysis and data mining. Assume we have a <code class="language-plaintext highlighter-rouge">classification</code> dataset in NLP. There are several aspects to think about.</p><ul><li><b>The Distribution.</b> To begin with, you need to know the <code class="language-plaintext highlighter-rouge">label</code> distribution especially and <code class="language-plaintext highlighter-rouge">visualize</code> it. For instance, if you observe <code class="language-plaintext highlighter-rouge">long-tailed distribution</code> (e.g. the number of the instances for good emotion is 900 while for the bad emotion is 10), then some methods such as data augmentation or cost-sensitive loss functions can play their part. For your interest, you can refer to this up-to-date <a href="https://arxiv.org/pdf/2110.04596.pdf">survey</a>. Similarly, you may also need to know the distribution of the <code class="language-plaintext highlighter-rouge">length</code> of sequence. Thus you can set the appropriate maximum sequence length for your task. Moreover, you can also pass the original data through the <code class="language-plaintext highlighter-rouge">feature extractor</code> (such as BERT) to gain their representation. Then you can <code class="language-plaintext highlighter-rouge">cluster</code> them.<li><b>Greed is good.</b> I strongly suggest that you <code class="language-plaintext highlighter-rouge">look through</code> the whole dataset ambitiously just like the <code class="language-plaintext highlighter-rouge">greedy algorithm</code>. And I promise you are bound to find surprise. You can have a whole understanding of the <code class="language-plaintext highlighter-rouge">domain</code> of this dataset. And you can choose appropriate <code class="language-plaintext highlighter-rouge">pre-trained</code> models according to the domain. Also, remember to understand the <code class="language-plaintext highlighter-rouge">labels</code>. Once you understand the labels, you can see if the annotation is <code class="language-plaintext highlighter-rouge">contradictory</code>. And you can select certain samples to see the annotation and estimate how noisy the whole dataset is. You may also need to think for the <code class="language-plaintext highlighter-rouge">machine</code>. Are the sequences easy to understand? If they are easy to understand, then we do not need to apply very complicated models to tackle this problem. Is the <code class="language-plaintext highlighter-rouge">local</code> information more important than the <code class="language-plaintext highlighter-rouge">global</code>? Your understanding about the dataset can help you figure out some basic modeling problems and offer you intuition about <code class="language-plaintext highlighter-rouge">rule-based</code> methods.<li><b>Simple quantification.</b> You may need to know the <code class="language-plaintext highlighter-rouge">size</code> of the dataset. If the size is <code class="language-plaintext highlighter-rouge">small</code>, we can use the simple models such as textCNN or FastText instead of BERT-based models for the complicated models need more data to model the inductive bias. Also, you can write simple code for detecting the <code class="language-plaintext highlighter-rouge">duplicate</code> instances and instances which are <code class="language-plaintext highlighter-rouge">corrupted</code> (e.g. lack of the label).<li><b>Stand on the shoulder of the model.</b> When your model is trained on the dataset, you can see how it performs on the <code class="language-plaintext highlighter-rouge">dev/eval</code> set. You need to pay attention to those <code class="language-plaintext highlighter-rouge">mis-predicted</code> instances (i.e. bad cases) and think about why the prediction is wrong. Is the label wrong or the way of modeling weak to capture these information.<li><b>Filter / Sort / Clean</b>. You can decide whether to filter or clean the dataset based on your thorough observation.</ul><h3 id="2-end-to-end-pipeline"><span class="mr-2">2. End-to-End Pipeline</span><a href="#2-end-to-end-pipeline" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>When you finish observing the dataset, you need to build the simple pipeline to ensure everything goes well.</p><ul><li><b>Fix the random seed.</b> When carrying out the experiments, you had better fix the seed to reduce the influences of <code class="language-plaintext highlighter-rouge">randomness</code> on the experiments.<li><b>As simple as possible.</b> When building the pipeline, you do not have to use very complicated modeling methods, etc. We are just testing. Thus make everything as simple as possible. For instance, you can use the simple classifier such as SVM and MLP (Multi-Layer Perceptron).<li><b>Record the accuracy and loss.</b> Training accuracy and loss are very useful for you to figure out which <code class="language-plaintext highlighter-rouge">difference</code> is beneficial. Also, we do not need complicated tools (e.g. Tensorboard and Wandb) to do so. You can use a list to store things you want and visualize it by matplotlib or write it down in a <code class="language-plaintext highlighter-rouge">txt</code> (Sometimes, the data on the terminal can disappear for certain reasons).<li><b>Track the progress.</b> In python, you can simply use the <code class="language-plaintext highlighter-rouge">tqdm</code> to track the progress. And you can also add the immediate accuracy and loss on the progress bar. Believe me, this can reduce your anxiety.<li><b>Verify the init loss.</b> For the multi-label classification problem, its loss should equal $-\log (1/ \text{num classes})$ (with a softmax). For instance, if you need to make the true prediction among 4 labels, the init loss should equal $1.386$.<li><b>Good Initialization.</b> For regression problems, if the <code class="language-plaintext highlighter-rouge">average</code> of your data is 6, then you can initialize the bias as 6 which can lead to <code class="language-plaintext highlighter-rouge">fast</code> and stable convergence. One more example, if you want to initialize the weights and you do not want the weights to be influenced by the <code class="language-plaintext highlighter-rouge">output shape</code>, then you may prefer Lecun Normal to Glorot Normal (all initialize with $\text{N(0, scale)}$). Also, <code class="language-plaintext highlighter-rouge">normal</code> initialization is better than uniform initialization by experience. Last but not least, when facing an <code class="language-plaintext highlighter-rouge">imblanced</code> dataset with ratio 1:10 (positive cases V.S. negative cases), set the bias on the <code class="language-plaintext highlighter-rouge">logits</code> so that the model can learn the bias with the first few iterations.<div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>  <span class="c1"># fan_in, fan_out represent the input and output shape
</span>  <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.</span>
  <span class="c1"># lecun normal
</span>  <span class="n">scale_lecun</span> <span class="o">/=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">fan_in</span><span class="p">)</span>
  <span class="n">scale_lecun</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">scale_lecun</span><span class="p">)</span>
	
  <span class="c1"># glorot normal
</span>  <span class="n">scale_glorot</span> <span class="o">/=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">fan_in</span> <span class="o">+</span> <span class="n">fan_out</span><span class="p">)</span>
  <span class="n">scale_glorot</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">scale_glorot</span><span class="p">)</span>
</pre></table></code></div></div><li><b>Human Baseline.</b> If the dataset is very particular and there are few related evaluation methods, you had better set the <code class="language-plaintext highlighter-rouge">human baseline</code> in sampled instances. Compared to the human baseline, you can have an idea that where your model has gone.<li><b>Input-Independent Baseline.</b> You can set the input all <code class="language-plaintext highlighter-rouge">zeros</code> and see the performance. And it should be <code class="language-plaintext highlighter-rouge">worse</code> than the performance of plugging in your data.<li><b>Overfit a small batch.</b> The model should <code class="language-plaintext highlighter-rouge">overfit</code> a batch of few instances (e.g. 10 or 20). Theoretically speaking, you should achieve the least loss. If the model fails to do so, then you can go and find the foxy bug.<li><b>Visualize the input before going into the NN.</b> Take Google’s <a href="https://github.com/google-research/bert">code</a> as example, it shows the input tensors when performing classification problems by BERT. This habit has saved me many times when coming up with a brand-new task because the preparation of data can be hard to some degree.<li><b>Visualize the predictions dynamically over the course of training.</b> By doing so, we can have a direct picture about where the model has gone and how it performs.<li><b>Try Back-Propogation yourself.</b> <code class="language-plaintext highlighter-rouge">Gradients</code> can give you information about what the model depends on to make such predictions.<li><b>Generalize a special case.</b> You should not write the general functions at the beginning because your thoughts can be easy to change, thus these general functions are fragile. You can generalize a special case when you are sure that it won’t change a lot.</ul><h3 id="3-overfitting"><span class="mr-2">3. Overfitting</span><a href="#3-overfitting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Since we have built a pipeline and tested it, it’s time for us to make the model overfit the whole dataset.</p><ul><li><b>Picking the right model.</b> The selection of models is related to the size of the dataset and complexity of the task. If your dataset is small, you can choose relatively big models to overfit.<li><b>Borrow experience from the giants.</b> Sometimes you are unfamiliar with the task, you may have no idea about which <code class="language-plaintext highlighter-rouge">hyper-parameter</code> to choose (e.g. learning rate). Then you can search some related papers and see the <code class="language-plaintext highlighter-rouge">appendix</code> for training details.<li><b>Carry out many controlled experiments.</b> Deep Learning is a <code class="language-plaintext highlighter-rouge">experimental subject</code>. Sometimes observation fails to give you idea about what exactly it will perform. For instance, if you want to know which learning rate is most suitable for this task, try more options to select the best. Remember change a variable <code class="language-plaintext highlighter-rouge">once a time</code> to reduce the influence of mixture.<li><b>Turn to tricks.</b> Tricks are infinite. For instance, you can apply adversarial training like FGM or PGD to improve the model’s performance. Also, if permitted, you can use <code class="language-plaintext highlighter-rouge">random</code> searching for the best parameters.</ul><h3 id="4-regularize"><span class="mr-2">4. Regularize</span><a href="#4-regularize" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li><b>More data is better.</b> The most effective way to regularize the model is collecting more real-world data for training. After all, we are using the <code class="language-plaintext highlighter-rouge">small</code> set of data to <code class="language-plaintext highlighter-rouge">approximate</code> the distribution of the real-world.<li><b>Data Augmentation.</b> If you <code class="language-plaintext highlighter-rouge">lack</code> data, you can apply data augmentation to increase your data. Although this method seems very easy, it does <code class="language-plaintext highlighter-rouge">demand</code> your thorough understanding of your data and task. And <code class="language-plaintext highlighter-rouge">creative</code> methods can always pay off. For instance, in NLP, you can use back-translation to augment.<li><b>Cross Validation.</b> You can split the data several times. And use separate data to train some models. Then we can ensemble them to gain the final prediction.</ul><h3 id="5-others"><span class="mr-2">5. Others</span><a href="#5-others" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li><b>Always remember to record your results in a good order.</b> For instance, you must record all the parameters and the model’s performances at the dev/eval set. You had better record the <code class="language-plaintext highlighter-rouge">motivation</code> for you trying out this experiment.<li><b>Always back up your code and data.</b> When you are trying some new methods, do not just try it on the original code. The same for the data. You need to back up the original pipeline and data for bad things happening.</ul><hr><h4>Sponsoring</h4><p>If you think of something really helpful, please consider sponsoring me! Any support is well appreciated! &#128516;&#128516;&#128516;</p><a href="https://ko-fi.com/yunpengtai"><img data-src="https://img.shields.io/badge/-Buy%20Me%20a%20Coffee-ff5f5f?logo=ko-fi&amp;logoColor=https://s2.loli.net/white" data-proofer-ignore></a> <a href="https://s2.loli.net/2022/06/19/wfh2rnYBq8vzZuD.jpg"><img data-src="https://img.shields.io/badge/-Tip%20Me%20on%20WeChat-brightgreen?logo=wechat&logoColor=https://s2.loli.net/white" data-proofer-ignore> </a> <a href="https://s2.loli.net/2022/06/19/kxm7wo8f3zTrcWt.jpg"><img data-src="https://img.shields.io/badge/-Tip%20Me%20on%20Alipay-blue?logo=alipay&logoColor=https://s2.loli.net/white" data-proofer-ignore></a></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/training/'>Training</a>, <a href='/categories/deep-learning/'>Deep Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/experience/" class="post-tag no-text-decoration" >Experience</a> <a href="/tags/neural-networks/" class="post-tag no-text-decoration" >Neural Networks</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Tips+for+Training+Neural+Networks+-+Yunpeng+Tai&url=https%3A%2F%2Fwww.yunpengtai.top%2Fposts%2FTips-for-Training-Neural-Networks%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Tips+for+Training+Neural+Networks+-+Yunpeng+Tai&u=https%3A%2F%2Fwww.yunpengtai.top%2Fposts%2FTips-for-Training-Neural-Networks%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fwww.yunpengtai.top%2Fposts%2FTips-for-Training-Neural-Networks%2F&text=Tips+for+Training+Neural+Networks+-+Yunpeng+Tai" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Back-propagation/">Going Deeper into Back-propagation</a><li><a href="/posts/Diving-in-distributed-training/">Diving in distributed training in PyTorch</a><li><a href="/posts/hello-world/">Hello World</a><li><a href="/posts/Tips-for-Training-Neural-Networks/">Tips for Training Neural Networks</a><li><a href="/posts/Quotes-of-Mathematicians/">Quotes of Mathematicians</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/1st-post/">1st post</a> <a class="post-tag" href="/tags/dataparallel/">DataParallel</a> <a class="post-tag" href="/tags/distributed-training/">Distributed Training</a> <a class="post-tag" href="/tags/experience/">Experience</a> <a class="post-tag" href="/tags/gradients/">Gradients</a> <a class="post-tag" href="/tags/hello-world/">hello world</a> <a class="post-tag" href="/tags/mathematics/">Mathematics</a> <a class="post-tag" href="/tags/multi-gpus/">Multi-gpus</a> <a class="post-tag" href="/tags/neural-networks/">Neural Networks</a> <a class="post-tag" href="/tags/optimization/">Optimization</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Back-propagation/"><div class="card-body"> <em class="small" data-ts="1662520200" data-df="ll" > Sep 7, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Going Deeper into Back-propagation</h3><div class="text-muted small"><p> 1. Gradient descent optimization Gradient-based methods make use of the gradient information to adjust the parameters. Among them, gradient descent can be the simplest. Gradient descent makes the ...</p></div></div></a></div><div class="card"> <a href="/posts/Diving-in-distributed-training/"><div class="card-body"> <em class="small" data-ts="1668951420" data-df="ll" > Nov 20, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Diving in distributed training in PyTorch</h3><div class="text-muted small"><p> 鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！ 关于此部分的代码，可以去这里查看 在开始前，我需要特别致谢一下一位挚友，他送了我双显卡的机器来赞助我做个人研究，否则多卡的相关实验就得付费在云平台上跑了，感谢好朋友一路以来的支持，这份恩情值得一辈子铭记！这篇文章作为礼物赠与挚友。 Why Parallel 我们...</p></div></div></a></div><div class="card"> <a href="/posts/Quotes-of-Mathematicians/"><div class="card-body"> <em class="small" data-ts="1658541360" data-df="ll" > Jul 23, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Quotes of Mathematicians</h3><div class="text-muted small"><p> Life is complex, and it has both real and imaginary parts. — Someone Basically, I’m not interested in doing research and I never have been… I’m interested in understanding, which is quite a di...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Quotes-of-Mathematicians/" class="btn btn-outline-primary" prompt="Older"><p>Quotes of Mathematicians</p></a> <a href="/posts/Back-propagation/" class="btn btn-outline-primary" prompt="Newer"><p>Going Deeper into Back-propagation</p></a></div><script src="https://unpkg.com/@waline/client@v2/dist/waline.js"></script><link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css" /><div id="waline"></div><script> $(function() { const locale = { placeholder: '可以匿名评论哦~ QQ邮箱可自动获取头像 Anything to say? It can be anonymous.', level0: '潜水', level1: '冒泡', level2: '摸鱼', level3: '话痨', level4: '话满天', level5: '龙王', }; Waline.init({ el: '#waline', lang: 'en', reaction: true, serverURL: 'https://example.yunpengtai.top/', emoji: [ 'https://gcore.jsdelivr.net/gh/norevi/waline-blobcatemojis@1.0/blobs', 'https://unpkg.com/@waline/emojis@1.1.0/tw-emoji', 'https://unpkg.com/@waline/emojis@1.1.0/bmoji' ], reaction:[ 'https://gcore.jsdelivr.net/gh/norevi/waline-blobcatemojis@1.0/blobs/ablobcatheart.png', 'https://gcore.jsdelivr.net/gh/norevi/waline-blobcatemojis@1.0/blobs/ablobcatrainbow.png', 'https://gcore.jsdelivr.net/gh/norevi/waline-blobcatemojis@1.0/blobs/ablobcatattentionreverse.png', 'https://gcore.jsdelivr.net/gh/norevi/waline-blobcatemojis@1.0/blobs/ablobcatheartbroken.png', 'https://gcore.jsdelivr.net/gh/norevi/waline-blobcatemojis@1.0/blobs/blobcatopenmouth.png', 'https://gcore.jsdelivr.net/gh/norevi/waline-blobcatemojis@1.0/blobs/blobcatcoffee.png' ], dark: "__waline__css__", locale, }); let head = document.getElementsByTagName("head")[0]; let css = head.lastChild; let cssContent = css.textContent.replace("__waline__css__", ""); let cssContentPerferredDark = "@media (prefers-color-scheme: dark){html:not([data-mode])" + cssContent + "}"; let cssContentSelectedDark = "html[data-mode=dark]" + cssContent; css.textContent = cssContentPerferredDark; let style = document.createElement('style'); style.textContent = cssContentSelectedDark; head.appendChild(style); }); </script></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/TonySta14611077">Yunpeng Tai</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/1st-post/">1st post</a> <a class="post-tag" href="/tags/dataparallel/">DataParallel</a> <a class="post-tag" href="/tags/distributed-training/">Distributed Training</a> <a class="post-tag" href="/tags/experience/">Experience</a> <a class="post-tag" href="/tags/gradients/">Gradients</a> <a class="post-tag" href="/tags/hello-world/">hello world</a> <a class="post-tag" href="/tags/mathematics/">Mathematics</a> <a class="post-tag" href="/tags/multi-gpus/">Multi-gpus</a> <a class="post-tag" href="/tags/neural-networks/">Neural Networks</a> <a class="post-tag" href="/tags/optimization/">Optimization</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-Y3CX2RWEDY"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-Y3CX2RWEDY'); }); </script>
